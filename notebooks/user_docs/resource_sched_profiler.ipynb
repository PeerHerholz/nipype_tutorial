{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Scheduling and Profiling with Nipype\n",
    "\n",
    "The latest version of Nipype supports system resource scheduling and profiling. These features allows users to ensure high throughput of their data processing while also controlling the amount of computing resources a given workflow will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Resources in the Node Interface\n",
    "\n",
    "Each ``Node`` instance interface has two parameters that specify its expected thread and memory usage: ``num_threads`` and ``estimated_memory_gb``. If a particular node is expected to use 8 threads and 2 GB of memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "node = pe.Node()\n",
    "node.interface.num_threads = 8\n",
    "node.interface.estimated_memory_gb = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the resource parameters are never set, they default to being 1 thread and 1 GB of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Scheduler\n",
    "\n",
    "The ``MultiProc`` workflow plugin schedules node execution based on the resources used by the current running nodes and the total resources available to the workflow. The plugin utilizes the plugin arguments ``n_procs`` and ``memory_gb`` to set the maximum resources a workflow can utilize. To limit a workflow to using 8 cores and 10 GB of RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'n_procs' : 8, 'memory_gb' : 10}\n",
    "workflow.run(plugin='MultiProc', plugin_args=args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these values are not specifically set then the plugin will assume it can use all of the processors and memory on the system. For example, if the machine has 16 cores and 12 GB of RAM, the workflow will internally assume those values for ``n_procs`` and ``memory_gb``, respectively.\n",
    "\n",
    "The plugin will then queue eligible nodes for execution based on their expected usage via the ``num_threads`` and ``estimated_memory_gb`` interface parameters. If the plugin sees that only 3 of its 8 processors and 4 GB of its 10 GB of RAM are being used by running nodes, it will attempt to execute the next available node as long as its ``num_threads <= 5`` and ``estimated_memory_gb  <= 6``. If this is not the case, it will continue to check every available node in the queue until it sees a node that meets these conditions, or it waits for an executing node to finish to earn back the necessary resources. The priority of the queue is highest for nodes with the most ``estimated_memory_gb`` followed by nodes with the most expected ``num_threads``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Profiler and using the Callback Log\n",
    "\n",
    "It is not always easy to estimate the amount of resources a particular function or command uses. To help with this, Nipype provides some feedback about the system resources used by every node during workflow execution via the built-in runtime profiler. The runtime profiler is automatically enabled if the [psutil](https://pythonhosted.org/psutil/) Python package is installed and found on the system.\n",
    "\n",
    "If the package is not found, the workflow will run normally without the runtime profiler.\n",
    "\n",
    "The runtime profiler records the number of threads and the amount of memory (GB) used as ``runtime_threads`` and ``runtime_memory_gb`` in the Node's ``result.runtime`` attribute. Since the node object is pickled and written to disk in its working directory, these values are available for analysis after node or workflow execution by manually parsing the pickle file contents.\n",
    "\n",
    "Nipype also provides a logging mechanism for saving node runtime statistics to a JSON-style log file via the ``log_nodes_cb`` logger function. This is enabled by setting the ``status_callback`` parameter to point to this function in the ``plugin_args`` when using the ``MultiProc`` plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.utils.profiler import log_nodes_cb\n",
    "args_dict = {'n_procs' : 8, 'memory_gb' : 10, 'status_callback' : log_nodes_cb}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the filepath for the callback log the ``'callback'`` logger must be configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to log file\n",
    "import logging\n",
    "callback_log_path = '/home/user/run_stats.log'\n",
    "logger = logging.getLogger('callback')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.FileHandler(callback_log_path)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the workflow can be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.run(plugin='MultiProc', plugin_args=args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the workflow finishes executing, the log file at `/home/user/run_stats.log` can be parsed for the runtime statistics. Here is an example of what the contents would look like:\n",
    "\n",
    "```python\n",
    "{\"name\":\"resample_node\",\"id\":\"resample_node\",\n",
    " \"start\":\"2016-03-11 21:43:41.682258\",\n",
    " \"estimated_memory_gb\":2,\"num_threads\":1}\n",
    "{\"name\":\"resample_node\",\"id\":\"resample_node\",\n",
    "\"finish\":\"2016-03-11 21:44:28.357519\",\n",
    "\"estimated_memory_gb\":\"2\",\"num_threads\":\"1\",\n",
    "\"runtime_threads\":\"3\",\"runtime_memory_gb\":\"1.118469238281\"}\n",
    "```\n",
    "\n",
    "Here it can be seen that the number of threads was underestimated while the amount of memory needed was overestimated. The next time this workflow is run the user can change the node interface ``num_threads`` and ``estimated_memory_gb`` parameters to reflect this for a higher pipeline throughput. Note, sometimes the \"runtime_threads\" value is higher than expected, particularly for multi-threaded applications. Tools can implement multi-threading in different ways under-the-hood; the profiler merely traverses the process tree to return all running threads associated with that process, some of which may include active thread-monitoring daemons or transient processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Pipeline Resources\n",
    "\n",
    "Nipype provides the ability to visualize the workflow execution based on the runtimes and system resources each node takes. It does this using the log file generated from the callback logger after workflow execution - as shown above. The [pandas](http://pandas.pydata.org/) Python package is required to use this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.utils.profiler import log_nodes_cb\n",
    "args_dict = {'n_procs' : 8, 'memory_gb' : 10, 'status_callback' : log_nodes_cb}\n",
    "workflow.run(plugin='MultiProc', plugin_args=args_dict)\n",
    "\n",
    "# ...workflow finishes and writes callback log to '/home/user/run_stats.log'\n",
    "\n",
    "from nipype.utils.draw_gantt_chart import generate_gantt_chart\n",
    "generate_gantt_chart('/home/user/run_stats.log', cores=8)\n",
    "# ...creates gantt chart in '/home/user/run_stats.log.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``generate_gantt_chart`` function will create an html file that can be viewed in a browser. Below is an example of the gantt chart displayed in a web browser. Note that when the cursor is hovered over any particular node bubble or resource bubble, some additional information is shown in a pop-up.\n",
    "\n",
    "<img src=\"../../static/images/gantt_chart.png\", width=\"720\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
