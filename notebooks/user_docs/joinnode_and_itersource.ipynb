{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JoinNode, synchronize and itersource\n",
    "\n",
    "The previous [MapNode, iterfield, and iterables explained](mapnode_and_iterables.ipynb) chapter described how to fork and join nodes using MapNode and iterables. In this chapter, we introduce features which build on these concepts to add workflow flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JoinNode, joinsource and joinfield\n",
    "\n",
    "A `nipype.pipeline.engine.JoinNode` generalizes MapNode to operate in conjunction with an upstream iterable node to reassemble downstream results, e.g.:\n",
    "\n",
    "<img src=\"../../static/images/joinnode.png\", width=\"250\">\n",
    "\n",
    "The code to achieve this is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "a = pe.Node(interface=A(), name=\"a\")\n",
    "b = pe.Node(interface=B(), name=\"b\")\n",
    "b.iterables = (\"in_file\", images)\n",
    "c = pe.Node(interface=C(), name=\"c\")\n",
    "d = pe.JoinNode(interface=D(), joinsource=\"b\",\n",
    "                joinfield=\"in_files\", name=\"d\")\n",
    "\n",
    "my_workflow = pe.Workflow(name=\"my_workflow\")\n",
    "my_workflow.connect([(a,b,[('subject','subject')]),\n",
    "                     (b,c,[('out_file','in_file')])\n",
    "                     (c,d,[('out_file','in_files')])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example assumes that interface `A` has one output *subject*, interface `B` has two inputs *subject* and *in_file* and one output *out_file*, interface `C` has one input *in_file* and one output *out_file*, and interface `D` has one list input *in_files*. The *images* variable is a list of three input image file names.\n",
    "\n",
    "As with *iterables* and the MapNode *iterfield*, the *joinfield* can be a list of fields. Thus, the declaration in the previous example is equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pe.JoinNode(interface=D(), joinsource=\"b\",\n",
    "                joinfield=[\"in_files\"], name=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *joinfield* defaults to all of the JoinNode input fields, so the declaration is also equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pe.JoinNode(interface=D(), joinsource=\"b\", name=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the node `C` *out_file* outputs are collected into the JoinNode `D` *in_files* input list. The *in_files* order is the same as the upstream `B` node iterables order.\n",
    "\n",
    "The JoinNode input can be filtered for unique values by specifying the *unique* flag, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pe.JoinNode(interface=D(), joinsource=\"b\", unique=True, name=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synchronize\n",
    "\n",
    "The `nipype.pipeline.engine.Node` *iterables* parameter can be be a single field or a list of fields. If it is a list, then execution is performed over all permutations of the list items. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.iterables = [(\"m\", [1, 2]), (\"n\", [3, 4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results in the execution graph:\n",
    "\n",
    "<img src=\"../../static/images/synchronize_1.png\", width=\"350\">\n",
    "\n",
    "where `B13` has inputs *m* = 1, *n* = 3, `B14` has inputs  *m* = 1,\n",
    "*n* = 4, etc.\n",
    "\n",
    "The *synchronize* parameter synchronizes the iterables lists, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.iterables = [(\"m\", [1, 2]), (\"n\", [3, 4])]\n",
    "b.synchronize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results in the execution graph:\n",
    "\n",
    "<img src=\"../../static/images/synchronize_2.png\", width=\"165\">\n",
    "\n",
    "where the iterable inputs are selected in lock-step by index, i.e.:\n",
    "\n",
    "    (*m*, *n*) = (1, 3) and (2, 4)\n",
    "\n",
    "for `B13` and `B24`, resp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## itersource\n",
    "\n",
    "The *itersource* feature allows you to expand a downstream iterable based on a mapping of an upstream iterable. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pe.Node(interface=A(), name=\"a\")\n",
    "b = pe.Node(interface=B(), name=\"b\")\n",
    "b.iterables = (\"m\", [1, 2])\n",
    "c = pe.Node(interface=C(), name=\"c\")\n",
    "d = pe.Node(interface=D(), name=\"d\")\n",
    "d.itersource = (\"b\", \"m\")\n",
    "d.iterables = [(\"n\", {1:[3,4], 2:[5,6]})]\n",
    "my_workflow = pe.Workflow(name=\"my_workflow\")\n",
    "my_workflow.connect([(a,b,[('out_file','in_file')]),\n",
    "                     (b,c,[('out_file','in_file')])\n",
    "                     (c,d,[('out_file','in_file')])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results in the execution graph:\n",
    "\n",
    "<img src=\"../../static/images/itersource_1.png\", width=\"350\">\n",
    "\n",
    "In this example, all interfaces have input *in_file* and output *out_file*. In addition, interface `B` has input *m* and interface `D` has input *n*. A Python dictionary associates the `B` node input value with the downstream `D` node *n* iterable values.\n",
    "\n",
    "This example can be extended with a summary JoinNode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = pe.JoinNode(interface=E(), joinsource=\"d\",\n",
    "            joinfield=\"in_files\", name=\"e\")\n",
    "my_workflow.connect(d, 'out_file',\n",
    "                  e, 'in_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting in the graph:\n",
    "\n",
    "<img src=\"../../static/images/itersource_2.png\", width=\"350\">\n",
    "\n",
    "The combination of iterables, MapNode, JoinNode, synchronize and itersource enables the creation of arbitrarily complex workflow graphs. The astute workflow builder will recognize that this flexibility is both a blessing and a curse. These advanced features are handy additions to the Nipype toolkit when used judiciously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
